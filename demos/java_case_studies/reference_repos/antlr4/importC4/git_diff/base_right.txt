diff --git a/java_case_studies/reference_repos/antlr4/importC4/base.java b/java_case_studies/reference_repos/antlr4/importC4/right.java
index e038357..1ffab14 100644
--- a/java_case_studies/reference_repos/antlr4/importC4/base.java
+++ b/java_case_studies/reference_repos/antlr4/importC4/right.java
@@ -29,7 +29,13 @@
 
 package org.antlr.v4.runtime;
 
-import java.util.*;
+import org.antlr.v4.runtime.misc.Interval;
+import org.antlr.v4.runtime.misc.NotNull;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 
 /** Buffer all input tokens but do on-demand fetching of new tokens from
  *  lexer. Useful when the parser or lexer has to set context/mode info before
@@ -45,7 +51,7 @@ import java.util.*;
  *  This is not a subclass of UnbufferedTokenStream because I don't want
  *  to confuse small moving window of tokens it uses for the full buffer.
  */
-public class BufferedTokenStream<T extends Token> implements TokenStream {
+public class BufferedTokenStream implements TokenStream {
     protected TokenSource tokenSource;
 
     /** Record every single token pulled from the source so we can reproduce
@@ -53,7 +59,7 @@ public class BufferedTokenStream<T extends Token> implements TokenStream {
      *  as its moving window moves through the input.  This list captures
      *  everything so we can access complete input text.
      */
-    protected List<T> tokens = new ArrayList<T>(100);
+    protected List<Token> tokens = new ArrayList<Token>(100);
 
     /** Track the last mark() call result value for use in rewind(). */
     protected int lastMarker;
@@ -130,7 +136,7 @@ public class BufferedTokenStream<T extends Token> implements TokenStream {
     /** add n elements to buffer */
     protected void fetch(int n) {
         for (int i=1; i<=n; i++) {
-            T t = (T)tokenSource.nextToken();
+            Token t = tokenSource.nextToken();
             if ( t instanceof WritableToken ) {
                 ((WritableToken)t).setTokenIndex(tokens.size());
             }
@@ -140,21 +146,21 @@ public class BufferedTokenStream<T extends Token> implements TokenStream {
     }
 
     @Override
-    public T get(int i) {
+    public Token get(int i) {
         if ( i < 0 || i >= tokens.size() ) {
-            throw new NoSuchElementException("token index "+i+" out of range 0.."+(tokens.size()-1));
+            throw new IndexOutOfBoundsException("token index "+i+" out of range 0.."+(tokens.size()-1));
         }
         return tokens.get(i);
     }
 
 	/** Get all tokens from start..stop inclusively */
-	public List<T> get(int start, int stop) {
+	public List<Token> get(int start, int stop) {
 		if ( start<0 || stop<0 ) return null;
 		if ( p == -1 ) setup();
-		List<T> subset = new ArrayList<T>();
+		List<Token> subset = new ArrayList<Token>();
 		if ( stop>=tokens.size() ) stop = tokens.size()-1;
 		for (int i = start; i <= stop; i++) {
-			T t = tokens.get(i);
+			Token t = tokens.get(i);
 			if ( t.getType()==Token.EOF ) break;
 			subset.add(t);
 		}
@@ -164,13 +170,13 @@ public class BufferedTokenStream<T extends Token> implements TokenStream {
 	@Override
 	public int LA(int i) { return LT(i).getType(); }
 
-    protected T LB(int k) {
+    protected Token LB(int k) {
         if ( (p-k)<0 ) return null;
         return tokens.get(p-k);
     }
 
     @Override
-    public T LT(int k) {
+    public Token LT(int k) {
         if ( p == -1 ) setup();
         if ( k==0 ) return null;
         if ( k < 0 ) return LB(-k);
@@ -194,9 +200,9 @@ public class BufferedTokenStream<T extends Token> implements TokenStream {
         p = -1;
     }
 
-    public List<T> getTokens() { return tokens; }
+    public List<Token> getTokens() { return tokens; }
 
-    public List<T> getTokens(int start, int stop) {
+    public List<Token> getTokens(int start, int stop) {
         return getTokens(start, stop, null);
     }
 
@@ -204,16 +210,20 @@ public class BufferedTokenStream<T extends Token> implements TokenStream {
      *  the token type BitSet.  Return null if no tokens were found.  This
      *  method looks at both on and off channel tokens.
      */
-    public List<T> getTokens(int start, int stop, Set<Integer> types) {
+    public List<Token> getTokens(int start, int stop, Set<Integer> types) {
         if ( p == -1 ) setup();
-        if ( stop>=tokens.size() ) stop=tokens.size()-1;
-        if ( start<0 ) start=0;
+		if ( start<0 || stop>=tokens.size() ||
+			 stop<0  || start>=tokens.size() )
+		{
+			throw new IndexOutOfBoundsException("start "+start+" or stop "+stop+
+												" not in 0.."+(tokens.size()-1));
+		}
         if ( start>stop ) return null;
 
         // list = tokens[start:stop]:{T t, t.getType() in types}
-        List<T> filteredTokens = new ArrayList<T>();
+        List<Token> filteredTokens = new ArrayList<Token>();
         for (int i=start; i<=stop; i++) {
-            T t = tokens.get(i);
+            Token t = tokens.get(i);
             if ( types==null || types.contains(t.getType()) ) {
                 filteredTokens.add(t);
             }
@@ -224,43 +234,155 @@ public class BufferedTokenStream<T extends Token> implements TokenStream {
         return filteredTokens;
     }
 
-    public List<T> getTokens(int start, int stop, int ttype) {
+    public List<Token> getTokens(int start, int stop, int ttype) {
 		HashSet<Integer> s = new HashSet<Integer>(ttype);
 		s.add(ttype);
 		return getTokens(start,stop, s);
     }
 
-    @Override
+	/** Given a starting index, return the index of the next token on channel.
+	 *  Return i if tokens[i] is on channel.  Return -1 if there are no tokens
+	 *  on channel between i and EOF.
+	 */
+	protected int nextTokenOnChannel(int i, int channel) {
+		sync(i);
+		Token token = tokens.get(i);
+		if ( i>=size() ) return -1;
+		while ( token.getChannel()!=channel ) {
+			if ( token.getType()==Token.EOF ) return -1;
+			i++;
+			sync(i);
+			token = tokens.get(i);
+		}
+		return i;
+	}
+
+	/** Given a starting index, return the index of the previous token on channel.
+	 *  Return i if tokens[i] is on channel. Return -1 if there are no tokens
+	 *  on channel between i and 0.
+	 */
+	protected int previousTokenOnChannel(int i, int channel) {
+		while ( i>=0 && tokens.get(i).getChannel()!=channel ) {
+			i--;
+		}
+		return i;
+	}
+
+	/** Collect all tokens on specified channel to the right of
+	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or
+	 *  EOF. If channel is -1, find any non default channel token.
+	 */
+	public List<Token> getHiddenTokensToRight(int tokenIndex, int channel) {
+		if ( p == -1 ) setup();
+		if ( tokenIndex<0 || tokenIndex>=tokens.size() ) {
+			throw new IndexOutOfBoundsException(tokenIndex+" not in 0.."+(tokens.size()-1));
+		}
+
+		int nextOnChannel =
+			nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);
+		int to;
+		int from = tokenIndex+1;
+		// if none onchannel to right, nextOnChannel=-1 so set to = last token
+		if ( nextOnChannel == -1 ) to = size()-1;
+		else to = nextOnChannel;
+
+		return filterForChannel(from, to, channel);
+	}
+
+	/** Collect all hidden tokens (any off-default channel) to the right of
+	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL
+	 *  of EOF.
+	 */
+	public List<Token> getHiddenTokensToRight(int tokenIndex) {
+		return getHiddenTokensToRight(tokenIndex, -1);
+	}
+
+	/** Collect all tokens on specified channel to the left of
+	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
+	 *  If channel is -1, find any non default channel token.
+	 */
+	public List<Token> getHiddenTokensToLeft(int tokenIndex, int channel) {
+		if ( p == -1 ) setup();
+		if ( tokenIndex<0 || tokenIndex>=tokens.size() ) {
+			throw new IndexOutOfBoundsException(tokenIndex+" not in 0.."+(tokens.size()-1));
+		}
+
+		int prevOnChannel =
+			previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);
+		if ( prevOnChannel == tokenIndex - 1 ) return null;
+		// if none onchannel to left, prevOnChannel=-1 then from=0
+		int from = prevOnChannel+1;
+		int to = tokenIndex-1;
+
+		return filterForChannel(from, to, channel);
+	}
+
+	/** Collect all hidden tokens (any off-default channel) to the left of
+	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
+	 */
+	public List<Token> getHiddenTokensToLeft(int tokenIndex) {
+		return getHiddenTokensToLeft(tokenIndex, -1);
+	}
+
+	protected List<Token> filterForChannel(int from, int to, int channel) {
+		List<Token> hidden = new ArrayList<Token>();
+		for (int i=from; i<=to; i++) {
+			Token t = tokens.get(i);
+			if ( channel==-1 ) {
+				if ( t.getChannel()!= Lexer.DEFAULT_TOKEN_CHANNEL ) hidden.add(t);
+			}
+			else {
+				if ( t.getChannel()==channel ) hidden.add(t);
+			}
+		}
+		if ( hidden.size()==0 ) return null;
+		return hidden;
+	}
+
+	@Override
     public String getSourceName() {	return tokenSource.getSourceName();	}
 
-    /** Grab *all* tokens from stream and return string */
-    @Override
-    public String toString() {
-        if ( p == -1 ) setup();
-        fill();
-        return toString(0, tokens.size()-1);
-    }
+	/** Get the text of all tokens in this buffer. */
+	@NotNull
+	@Override
+	public String getText() {
+		if ( p == -1 ) setup();
+		fill();
+		return getText(Interval.of(0,size()-1));
+	}
 
+	@NotNull
     @Override
-    public String toString(int start, int stop) {
+    public String getText(Interval interval) {
+		int start = interval.a;
+		int stop = interval.b;
         if ( start<0 || stop<0 ) return "";
         if ( p == -1 ) setup();
         if ( stop>=tokens.size() ) stop = tokens.size()-1;
-        StringBuilder buf = new StringBuilder();
-        for (int i = start; i <= stop; i++) {
-            T t = tokens.get(i);
-            if ( t.getType()==Token.EOF ) break;
-            buf.append(t.getText());
-        }
-        return buf.toString();
+
+		StringBuilder buf = new StringBuilder();
+		for (int i = start; i <= stop; i++) {
+			Token t = tokens.get(i);
+			if ( t.getType()==Token.EOF ) break;
+			buf.append(t.getText());
+		}
+		return buf.toString();
     }
 
+	@NotNull
+	@Override
+	public String getText(RuleContext ctx) {
+		return getText(ctx.getSourceInterval());
+	}
+
+	@NotNull
     @Override
-    public String toString(Token start, Token stop) {
+    public String getText(Token start, Token stop) {
         if ( start!=null && stop!=null ) {
-            return toString(start.getTokenIndex(), stop.getTokenIndex());
+            return getText(Interval.of(start.getTokenIndex(), stop.getTokenIndex()));
         }
-        return null;
+
+		return "";
     }
 
     /** Get all tokens from lexer until EOF */
