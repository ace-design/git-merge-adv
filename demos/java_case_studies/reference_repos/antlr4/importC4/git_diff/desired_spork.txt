diff --git a/java_case_studies/reference_repos/antlr4/importC4/desired.java b/java_case_studies/reference_repos/antlr4/importC4/spork_result.java
index a17f63f..a5e3190 100644
--- a/java_case_studies/reference_repos/antlr4/importC4/desired.java
+++ b/java_case_studies/reference_repos/antlr4/importC4/spork_result.java
@@ -26,16 +26,15 @@
  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
-
 package org.antlr.v4.runtime;
 
-import org.antlr.v4.runtime.misc.Interval;
-import org.antlr.v4.runtime.misc.NotNull;
-
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
+import org.antlr.v4.runtime.misc.Interval;
+import org.antlr.v4.runtime.misc.NotNull;
+
 
 /** Buffer all input tokens but do on-demand fetching of new tokens from
  *  lexer. Useful when the parser or lexer has to set context/mode info before
@@ -52,7 +51,7 @@ import java.util.Set;
  *  to confuse small moving window of tokens it uses for the full buffer.
  */
 public class BufferedTokenStream implements TokenStream {
-	@NotNull
+    @NotNull
     protected TokenSource tokenSource;
 
     /** Record every single token pulled from the source so we can reproduce
@@ -69,27 +68,27 @@ public class BufferedTokenStream implements TokenStream {
      */
     protected int p = -1;
 
-	/**
-	 * Set to {@code true} when the EOF token is fetched. Do not continue fetching
-	 * tokens after that point, or multiple EOF tokens could end up in the
-	 * {@link #tokens} array.
-	 *
-	 * @see #fetch
-	 */
-	protected boolean fetchedEOF;
+    /**
+     * Set to {@code true} when the EOF token is fetched. Do not continue fetching
+     * tokens after that point, or multiple EOF tokens could end up in the
+     * {@link #tokens} array.
+     *
+     * @see #fetch
+     */
+    protected boolean fetchedEOF;
 
     public BufferedTokenStream(TokenSource tokenSource) {
-		if (tokenSource == null) {
-			throw new NullPointerException("tokenSource cannot be null");
-		}
+        if (tokenSource == null) {
+            throw new NullPointerException("tokenSource cannot be null");
+        }
         this.tokenSource = tokenSource;
     }
 
     @Override
     public TokenSource getTokenSource() { return tokenSource; }
 
-	@Override
-	public int index() { return p; }
+@Override
+public int index() { return p; }
 
 //	public int range() { return range; }
 
@@ -98,10 +97,10 @@ public class BufferedTokenStream implements TokenStream {
 		return 0;
 	}
 
-	@Override
-	public void release(int marker) {
-		// no resources to release
-	}
+@Override
+public void release(int marker) {
+	// no resources to release
+}
 
     public void reset() {
         seek(0);
@@ -114,136 +113,153 @@ public class BufferedTokenStream implements TokenStream {
     }
 
     @Override
-    public int size() { return tokens.size(); }
+    public int size() {
+        return tokens.size();
+    }
 
-    /** Move the input pointer to the next incoming token.  The stream
-     *  must become active with LT(1) available.  consume() simply
-     *  moves the input pointer so that LT(1) points at the next
-     *  input symbol. Consume at least one token, unless EOF has been reached.
+    /**
+     * Move the input pointer to the next incoming token.  The stream
+     * must become active with LT(1) available.  consume() simply
+     * moves the input pointer so that LT(1) points at the next
+     * input symbol. Consume at least one token, unless EOF has been reached.
      */
     @Override
     public void consume() {
         lazyInit();
-		if (sync(p + 1)) {
-			p = adjustSeekIndex(p + 1);
-		}
+        if (sync(p + 1)) {
+            p = adjustSeekIndex(p + 1);
+        }
     }
 
-    /** Make sure index {@code i} in tokens has a token.
-	 *
-	 * @return {@code true} if a token is located at index {@code i}, otherwise
-	 *    {@code false}.
-	 * @see #get(int i)
-	 */
+    /**
+     * Make sure index {@code i} in tokens has a token.
+     *
+     * @return {@code true} if a token is located at index {@code i}, otherwise
+    {@code false}.
+     * @see #get(int i)
+     */
     protected boolean sync(int i) {
-		assert i >= 0;
-        int n = i - tokens.size() + 1; // how many more elements we need?
+        assert i >= 0;
+        // how many more elements we need?
+        int n = (i - tokens.size()) + 1;
         //System.out.println("sync("+i+") needs "+n);
-        if ( n > 0 ) {
-			int fetched = fetch(n);
-			return fetched >= n;
-		}
-
-		return true;
+        if (n > 0) {
+            int fetched = fetch(n);
+            return fetched >= n;
+        }
+        return true;
     }
 
-    /** Add {@code n} elements to buffer.
-	 *
-	 * @return The actual number of elements added to the buffer.
-	 */
+    /**
+     * Add {@code n} elements to buffer.
+     *
+     * @return The actual number of elements added to the buffer.
+     */
     protected int fetch(int n) {
-		if (fetchedEOF) {
-			return 0;
-		}
-
+        if (fetchedEOF) {
+            return 0;
+        }
         for (int i = 0; i < n; i++) {
             Token t = tokenSource.nextToken();
-            if ( t instanceof WritableToken ) {
-                ((WritableToken)t).setTokenIndex(tokens.size());
+            if (t instanceof WritableToken) {
+                ((WritableToken) (t)).setTokenIndex(tokens.size());
             }
             tokens.add(t);
-            if ( t.getType()==Token.EOF ) {
-				fetchedEOF = true;
-				return i + 1;
-			}
+            if (t.getType() == Token.EOF) {
+                fetchedEOF = true;
+                return i + 1;
+            }
         }
-
-		return n;
+        return n;
     }
 
     @Override
     public Token get(int i) {
-        if ( i < 0 || i >= tokens.size() ) {
-            throw new IndexOutOfBoundsException("token index "+i+" out of range 0.."+(tokens.size()-1));
+        if ((i < 0) || (i >= tokens.size())) {
+            throw new IndexOutOfBoundsException((("token index " + i) + " out of range 0..") + (tokens.size() - 1));
         }
         return tokens.get(i);
     }
 
-	/** Get all tokens from start..stop inclusively */
-	public List<Token> get(int start, int stop) {
-		if ( start<0 || stop<0 ) return null;
-		lazyInit();
-		List<Token> subset = new ArrayList<Token>();
-		if ( stop>=tokens.size() ) stop = tokens.size()-1;
-		for (int i = start; i <= stop; i++) {
-			Token t = tokens.get(i);
-			if ( t.getType()==Token.EOF ) break;
-			subset.add(t);
-		}
-		return subset;
-	}
+/** Get all tokens from start..stop inclusively */
+    public List<Token> get(int start, int stop) {
+        if ((start < 0) || (stop < 0)) {
+            return null;
+        }
+        lazyInit();
+        List<Token> subset = new ArrayList<Token>();
+        if (stop >= tokens.size()) {
+            stop = tokens.size() - 1;
+        }
+        for (int i = start; i <= stop; i++) {
+            Token t = tokens.get(i);
+            if (t.getType() == Token.EOF) {
+                break;
+            }
+            subset.add(t);
+        }
+        return subset;
+    }
 
-	@Override
-	public int LA(int i) { return LT(i).getType(); }
+    @Override
+    public int LA(int i) {
+        return LT(i).getType();
+    }
 
     protected Token LB(int k) {
-        if ( (p-k)<0 ) return null;
-        return tokens.get(p-k);
+        if ((p - k) < 0) {
+            return null;
+        }
+        return tokens.get(p - k);
     }
 
     @Override
     public Token LT(int k) {
         lazyInit();
-        if ( k==0 ) return null;
-        if ( k < 0 ) return LB(-k);
-
-		int i = p + k - 1;
-		sync(i);
-        if ( i >= tokens.size() ) { // return EOF token
+        if (k == 0) {
+            return null;
+        }
+        if (k < 0) {
+            return LB(-k);
+        }
+        int i = (p + k) - 1;
+        sync(i);
+        if (i >= tokens.size()) {
+        // return EOF token
             // EOF must be last token
-            return tokens.get(tokens.size()-1);
+            return tokens.get(tokens.size() - 1);
         }
 //		if ( i>range ) range = i;
         return tokens.get(i);
     }
 
-	/**
-	 * Allowed derived classes to modify the behavior of operations which change
-	 * the current stream position by adjusting the target token index of a seek
-	 * operation. The default implementation simply returns {@code i}. If an
-	 * exception is thrown in this method, the current stream index should not be
-	 * changed.
-	 * <p>
-	 * For example, {@link CommonTokenStream} overrides this method to ensure that
-	 * the seek target is always an on-channel token.
-	 *
-	 * @param i The target token index.
-	 * @return The adjusted target token index.
-	 */
-	protected int adjustSeekIndex(int i) {
-		return i;
-	}
+/**
+ * Allowed derived classes to modify the behavior of operations which change
+ * the current stream position by adjusting the target token index of a seek
+ * operation. The default implementation simply returns {@code i}. If an
+ * exception is thrown in this method, the current stream index should not be
+ * changed.
+ * <p>
+ * For example, {@link CommonTokenStream} overrides this method to ensure that
+ * the seek target is always an on-channel token.
+ *
+ * @param i The target token index.
+ * @return The adjusted target token index.
+ */
+protected int adjustSeekIndex(int i) {
+	return i;
+}
 
-	protected final void lazyInit() {
-		if (p == -1) {
-			setup();
-		}
-	}
+    protected final void lazyInit() {
+        if (p == (-1)) {
+            setup();
+        }
+    }
 
     protected void setup() {
-		sync(0);
-		p = adjustSeekIndex(0);
-	}
+        sync(0);
+        p = adjustSeekIndex(0);
+    }
 
     /** Reset this token stream by setting its token source. */
     public void setTokenSource(TokenSource tokenSource) {
@@ -252,7 +268,9 @@ public class BufferedTokenStream implements TokenStream {
         p = -1;
     }
 
-    public List<Token> getTokens() { return tokens; }
+    public List<Token> getTokens() {
+        return tokens;
+    }
 
     public List<Token> getTokens(int start, int stop) {
         return getTokens(start, stop, null);
@@ -264,188 +282,199 @@ public class BufferedTokenStream implements TokenStream {
      */
     public List<Token> getTokens(int start, int stop, Set<Integer> types) {
         lazyInit();
-		if ( start<0 || stop>=tokens.size() ||
-			 stop<0  || start>=tokens.size() )
-		{
-			throw new IndexOutOfBoundsException("start "+start+" or stop "+stop+
-												" not in 0.."+(tokens.size()-1));
-		}
-        if ( start>stop ) return null;
-
+        if ((((start < 0) || (stop >= tokens.size())) || (stop < 0)) || (start >= tokens.size())) {
+            throw new IndexOutOfBoundsException((((("start " + start) + " or stop ") + stop) + " not in 0..") + (tokens.size() - 1));
+        }
+        if (start > stop) {
+            return null;
+        }
         // list = tokens[start:stop]:{T t, t.getType() in types}
         List<Token> filteredTokens = new ArrayList<Token>();
-        for (int i=start; i<=stop; i++) {
+        for (int i = start; i <= stop; i++) {
             Token t = tokens.get(i);
-            if ( types==null || types.contains(t.getType()) ) {
+            if ((types == null) || types.contains(t.getType())) {
                 filteredTokens.add(t);
             }
         }
-        if ( filteredTokens.isEmpty() ) {
+        if (filteredTokens.isEmpty()) {
             filteredTokens = null;
         }
         return filteredTokens;
     }
 
     public List<Token> getTokens(int start, int stop, int ttype) {
-		HashSet<Integer> s = new HashSet<Integer>(ttype);
-		s.add(ttype);
-		return getTokens(start,stop, s);
+        HashSet<Integer> s = new HashSet<Integer>(ttype);
+        s.add(ttype);
+        return getTokens(start, stop, s);
     }
 
-	/** Given a starting index, return the index of the next token on channel.
-	 *  Return i if tokens[i] is on channel.  Return -1 if there are no tokens
-	 *  on channel between i and EOF.
-	 */
-	protected int nextTokenOnChannel(int i, int channel) {
-		sync(i);
-		Token token = tokens.get(i);
-		if ( i>=size() ) return -1;
-		while ( token.getChannel()!=channel ) {
-			if ( token.getType()==Token.EOF ) return -1;
-			i++;
-			sync(i);
-			token = tokens.get(i);
-		}
-		return i;
-	}
+/** Given a starting index, return the index of the next token on channel.
+ *  Return i if tokens[i] is on channel.  Return -1 if there are no tokens
+ *  on channel between i and EOF.
+ */
+    protected int nextTokenOnChannel(int i, int channel) {
+        sync(i);
+        Token token = tokens.get(i);
+        if (i >= size()) {
+            return -1;
+        }
+        while (token.getChannel() != channel) {
+            if (token.getType() == Token.EOF) {
+                return -1;
+            }
+            i++;
+            sync(i);
+            token = tokens.get(i);
+        } 
+        return i;
+    }
 
-	/** Given a starting index, return the index of the previous token on channel.
-	 *  Return i if tokens[i] is on channel. Return -1 if there are no tokens
-	 *  on channel between i and 0.
-	 */
-	protected int previousTokenOnChannel(int i, int channel) {
-		while ( i>=0 && tokens.get(i).getChannel()!=channel ) {
-			i--;
-		}
-		return i;
+/** Given a starting index, return the index of the previous token on channel.
+ *  Return i if tokens[i] is on channel. Return -1 if there are no tokens
+ *  on channel between i and 0.
+ */
+protected int previousTokenOnChannel(int i, int channel) {
+	while ( i>=0 && tokens.get(i).getChannel()!=channel ) {
+		i--;
 	}
+	return i;
+}
 
-	/** Collect all tokens on specified channel to the right of
-	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or
-	 *  EOF. If channel is -1, find any non default channel token.
-	 */
-	public List<Token> getHiddenTokensToRight(int tokenIndex, int channel) {
-		lazyInit();
-		if ( tokenIndex<0 || tokenIndex>=tokens.size() ) {
-			throw new IndexOutOfBoundsException(tokenIndex+" not in 0.."+(tokens.size()-1));
-		}
+/** Collect all tokens on specified channel to the right of
+ *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or
+ *  EOF. If channel is -1, find any non default channel token.
+ */
+    public List<Token> getHiddenTokensToRight(int tokenIndex, int channel) {
+        if (p == (-1)) {
+            setup();
+        }
+        if ((tokenIndex < 0) || (tokenIndex >= tokens.size())) {
+            throw new IndexOutOfBoundsException((tokenIndex + " not in 0..") + (tokens.size() - 1));
+        }
+        int nextOnChannel = nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);
+        int to;
+        int from = tokenIndex + 1;
+        // if none onchannel to right, nextOnChannel=-1 so set to = last token
+        if (nextOnChannel == (-1)) {
+            to = size() - 1;
+        } else {
+            to = nextOnChannel;
+        }
+        return filterForChannel(from, to, channel);
+    }
 
-		int nextOnChannel =
-			nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);
-		int to;
-		int from = tokenIndex+1;
-		// if none onchannel to right, nextOnChannel=-1 so set to = last token
-		if ( nextOnChannel == -1 ) to = size()-1;
-		else to = nextOnChannel;
+/** Collect all hidden tokens (any off-default channel) to the right of
+ *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL
+ *  of EOF.
+ */
+public List<Token> getHiddenTokensToRight(int tokenIndex) {
+	return getHiddenTokensToRight(tokenIndex, -1);
+}
 
-		return filterForChannel(from, to, channel);
-	}
+/** Collect all tokens on specified channel to the left of
+ *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
+ *  If channel is -1, find any non default channel token.
+ */
+    public List<Token> getHiddenTokensToLeft(int tokenIndex, int channel) {
+        if (p == (-1)) {
+            setup();
+        }
+        if ((tokenIndex < 0) || (tokenIndex >= tokens.size())) {
+            throw new IndexOutOfBoundsException((tokenIndex + " not in 0..") + (tokens.size() - 1));
+        }
+        int prevOnChannel = previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);
+        if (prevOnChannel == (tokenIndex - 1)) {
+            return null;
+        }
+        // if none onchannel to left, prevOnChannel=-1 then from=0
+        int from = prevOnChannel + 1;
+        int to = tokenIndex - 1;
+        return filterForChannel(from, to, channel);
+    }
 
-	/** Collect all hidden tokens (any off-default channel) to the right of
-	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL
-	 *  of EOF.
-	 */
-	public List<Token> getHiddenTokensToRight(int tokenIndex) {
-		return getHiddenTokensToRight(tokenIndex, -1);
-	}
+/** Collect all hidden tokens (any off-default channel) to the left of
+ *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
+ */
+public List<Token> getHiddenTokensToLeft(int tokenIndex) {
+	return getHiddenTokensToLeft(tokenIndex, -1);
+}
 
-	/** Collect all tokens on specified channel to the left of
-	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
-	 *  If channel is -1, find any non default channel token.
-	 */
-	public List<Token> getHiddenTokensToLeft(int tokenIndex, int channel) {
-		lazyInit();
-		if ( tokenIndex<0 || tokenIndex>=tokens.size() ) {
-			throw new IndexOutOfBoundsException(tokenIndex+" not in 0.."+(tokens.size()-1));
+protected List<Token> filterForChannel(int from, int to, int channel) {
+	List<Token> hidden = new ArrayList<Token>();
+	for (int i=from; i<=to; i++) {
+		Token t = tokens.get(i);
+		if ( channel==-1 ) {
+			if ( t.getChannel()!= Lexer.DEFAULT_TOKEN_CHANNEL ) hidden.add(t);
 		}
-
-		int prevOnChannel =
-			previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);
-		if ( prevOnChannel == tokenIndex - 1 ) return null;
-		// if none onchannel to left, prevOnChannel=-1 then from=0
-		int from = prevOnChannel+1;
-		int to = tokenIndex-1;
-
-		return filterForChannel(from, to, channel);
-	}
-
-	/** Collect all hidden tokens (any off-default channel) to the left of
-	 *  the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
-	 */
-	public List<Token> getHiddenTokensToLeft(int tokenIndex) {
-		return getHiddenTokensToLeft(tokenIndex, -1);
-	}
-
-	protected List<Token> filterForChannel(int from, int to, int channel) {
-		List<Token> hidden = new ArrayList<Token>();
-		for (int i=from; i<=to; i++) {
-			Token t = tokens.get(i);
-			if ( channel==-1 ) {
-				if ( t.getChannel()!= Lexer.DEFAULT_TOKEN_CHANNEL ) hidden.add(t);
-			}
-			else {
-				if ( t.getChannel()==channel ) hidden.add(t);
-			}
+		else {
+			if ( t.getChannel()==channel ) hidden.add(t);
 		}
-		if ( hidden.size()==0 ) return null;
-		return hidden;
 	}
+	if ( hidden.size()==0 ) return null;
+	return hidden;
+}
 
-	@Override
+    @Override
     public String getSourceName() {	return tokenSource.getSourceName();	}
 
-	/** Get the text of all tokens in this buffer. */
-	@NotNull
-	@Override
-	public String getText() {
+    /**
+     * Get the text of all tokens in this buffer.
+     */
+    @NotNull
+    @Override
+    public String getText() {
         lazyInit();
-		fill();
-		return getText(Interval.of(0,size()-1));
-	}
+        fill();
+        return getText(Interval.of(0, size() - 1));
+    }
 
-	@NotNull
+    @NotNull
     @Override
     public String getText(Interval interval) {
-		int start = interval.a;
-		int stop = interval.b;
-        if ( start<0 || stop<0 ) return "";
+        int start = interval.a;
+        int stop = interval.b;
+        if ((start < 0) || (stop < 0)) {
+            return "";
+        }
         lazyInit();
-        if ( stop>=tokens.size() ) stop = tokens.size()-1;
-
-		StringBuilder buf = new StringBuilder();
-		for (int i = start; i <= stop; i++) {
-			Token t = tokens.get(i);
-			if ( t.getType()==Token.EOF ) break;
-			buf.append(t.getText());
-		}
-		return buf.toString();
+        if (stop >= tokens.size()) {
+            stop = tokens.size() - 1;
+        }
+        StringBuilder buf = new StringBuilder();
+        for (int i = start; i <= stop; i++) {
+            Token t = tokens.get(i);
+            if (t.getType() == Token.EOF) {
+                break;
+            }
+            buf.append(t.getText());
+        }
+        return buf.toString();
     }
 
-	@NotNull
-	@Override
-	public String getText(RuleContext ctx) {
-		return getText(ctx.getSourceInterval());
-	}
+@NotNull
+@Override
+public String getText(RuleContext ctx) {
+	return getText(ctx.getSourceInterval());
+}
 
-	@NotNull
+    @NotNull
     @Override
     public String getText(Token start, Token stop) {
-        if ( start!=null && stop!=null ) {
+        if ((start != null) && (stop != null)) {
             return getText(Interval.of(start.getTokenIndex(), stop.getTokenIndex()));
         }
-
-		return "";
+        return "";
     }
 
     /** Get all tokens from lexer until EOF */
     public void fill() {
         lazyInit();
-		final int blockSize = 1000;
-		while (true) {
-			int fetched = fetch(blockSize);
-			if (fetched < blockSize) {
-				return;
-			}
-		}
+        final int blockSize = 1000;
+        while (true) {
+            int fetched = fetch(blockSize);
+            if (fetched < blockSize) {
+                return;
+            }
+        } 
     }
 }
